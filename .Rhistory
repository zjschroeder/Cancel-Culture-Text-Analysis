#load data - twit_corp
rio::import(here::here("data/study1.csv"))
#load data - twit_corp
twitterdata = rio::import(here::here("data/study1.csv"))
twitterdata = read.csv(here::here("data/study1.csv"), nrows = 1000)
View(twitterdata)
#datawrangling
terms_corp<- corpus(twitterdata, text_field = "posttoken") #data to corpus
###############################################################################################
#PRE-PROCESSING DATA & CODE: The data and code in this section are conducted to produce the TFIDF file that will be available for replication data. The pre-processing data used in this section will NOT be made publicly available (per Twitter/X restrictions on data sharing), but we have made the code available.
###############################################################################################
library(quanteda)
#datawrangling
terms_corp<- corpus(twitterdata, text_field = "posttoken") #data to corpus
terms_Dfm <- dfm(terms_corp, verbose = FALSE) #corpus to dfm
#datawrangling
terms_toks <- tokens(twitterdata, text_field = "posttoken")
corpus
#datawrangling
terms_toks <- corpus(twitterdata, text_field = "posttoken")
terms_Dfm <- dfm(terms_corp, verbose = FALSE) #corpus to dfm
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% tokens()
View(terms_corp)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% as.tokens() #data to corpus
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% tokens() #data to corpus
View(terms_corp)
terms_corp[["text1"]]
terms_Dfm <- dfm(terms_corp, verbose = FALSE, remove_padding = TRUE) #corpus to dfm
View(terms_Dfm)
terms_Dfm2<- dfm_trim(terms_Dfm, min_docfreq = 0.001, docfreq_type = "prop")
terms_Dfm3 <- dfm_subset(terms_Dfm2, ntoken(terms_Dfm2) > 0)
data_terms_clean <- dfm_tfidf(terms_Dfm3)
data_terms_clean
View(data_terms_clean)
data_terms_clean@docvars
View(terms_corp)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") #data to corpus
terms_Dfm <- dfm(terms_corp, verbose = FALSE) #corpus to dfm
terms_Dfm
terms_Dfm2<- dfm_trim(terms_Dfm, min_docfreq = 0.001, docfreq_type = "prop")
terms_Dfm3 <- dfm_subset(terms_Dfm2, ntoken(terms_Dfm2) > 0)
data_terms_clean <- dfm_tfidf(terms_Dfm3)
View(data_terms_clean)
terms_corp
###############################################################################################
#PRE-PROCESSING DATA & CODE: The data and code in this section are conducted to produce the TFIDF file that will be available for replication data. The pre-processing data used in this section will NOT be made publicly available (per Twitter/X restrictions on data sharing), but we have made the code available.
###############################################################################################
library(quanteda)
#load data - twit_corp
twitterdata = read.csv(here::here("data/study1.csv"), nrows = 1000)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken")
terms_Dfm <- dfm(terms_corp, verbose = FALSE)
terms_Dfm2<- dfm_trim(terms_Dfm, min_docfreq = 0.001, docfreq_type = "prop")
terms_Dfm3 <- dfm_subset(terms_Dfm2, ntoken(terms_Dfm2) > 0)
data_terms_clean <- dfm_tfidf(terms_Dfm3)
#save(data_terms_clean, file = "replicationdata_terms.RData")
###############################################################################################
#REPLICATION DATA: The data and code for this section are available for study replication.
###############################################################################################
library(quanteda.textstats)
library(igraph)
#load TF-IDF file
#load("replicationdata_terms.RData")
#compute cosine similarity matrix
terms_cosine <- textstat_simil(data_terms_clean, margin = "features", method = "cosine")
#cosine matrix igraph object
terms_g <- graph_from_adjacency_matrix(as.matrix(terms_cosine), mode = "undirected", weighted = TRUE, diag = FALSE)
terms_g
twitterdata = read.csv(here::here("data/study1.csv"), nrows = 1000) %>%
mutate(
posttoken = gsub("[[:punct:]]", "", posttoken)
)
library(tidyverse)
#load data - twit_corp
twitterdata = read.csv(here::here("data/study1.csv"), nrows = 1000) %>%
mutate(
posttoken = gsub("[[:punct:]]", "", posttoken)
)
head(twitterdata$posttoken)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% token()
###############################################################################################
#PRE-PROCESSING DATA & CODE: The data and code in this section are conducted to produce the TFIDF file that will be available for replication data. The pre-processing data used in this section will NOT be made publicly available (per Twitter/X restrictions on data sharing), but we have made the code available.
###############################################################################################
library(quanteda)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% token()
twitterdata = read.csv(here::here("data/study1.csv"), nrows = 1000) %>%
mutate(
posttoken = gsub("[[:punct:]]", "", posttoken)
)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken")
terms_Dfm <- dfm(terms_corp, verbose = FALSE)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% tokens()
terms_Dfm <- dfm(terms_corp, verbose = FALSE)
terms_Dfm2<- dfm_trim(terms_Dfm, min_docfreq = 0.001, docfreq_type = "prop")
terms_Dfm3 <- dfm_subset(terms_Dfm2, ntoken(terms_Dfm2) > 0)
data_terms_clean <- dfm_tfidf(terms_Dfm3)
###############################################################################################
#PRE-PROCESSING DATA & CODE: The data and code in this section are conducted to produce the TFIDF file that will be available for replication data. The pre-processing data used in this section will NOT be made publicly available (per Twitter/X restrictions on data sharing), but we have made the code available.
###############################################################################################
library(quanteda)
library(tidyverse)
#load data - twit_corp
twitterdata = read.csv(here::here("data/study1.csv"), nrows = 1000) %>%
mutate(
posttoken = gsub("[[:punct:]]", "", posttoken)
)
#datawrangling
terms_corp <- corpus(twitterdata, text_field = "posttoken") %>% tokens()
terms_Dfm <- dfm(terms_corp, verbose = FALSE)
terms_Dfm2<- dfm_trim(terms_Dfm, min_docfreq = 0.001, docfreq_type = "prop")
terms_Dfm3 <- dfm_subset(terms_Dfm2, ntoken(terms_Dfm2) > 0)
data_terms_clean <- dfm_tfidf(terms_Dfm3)
#save(data_terms_clean, file = "replicationdata_terms.RData")
###############################################################################################
#REPLICATION DATA: The data and code for this section are available for study replication.
###############################################################################################
library(quanteda.textstats)
library(igraph)
#load TF-IDF file
#load("replicationdata_terms.RData")
#compute cosine similarity matrix
terms_cosine <- textstat_simil(data_terms_clean, margin = "features", method = "cosine")
#cosine matrix igraph object
terms_g <- graph_from_adjacency_matrix(as.matrix(terms_cosine), mode = "undirected", weighted = TRUE, diag = FALSE)
terms_g
View(terms_Dfm)
terms_Dfm@docvars
terms_Dfm@Dimnames
View(terms_cosine)
terms_cosine
matrix(terms_Dfm)
